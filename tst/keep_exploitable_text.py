import spacy

# Charger un modèle spaCy pour l'analyse linguistique
nlp = spacy.load("en_core_web_sm")  # Utilisez le modèle de votre langue (ex: "fr_core_news_sm" pour le français)

def is_exploitable(text):
    """
    Détermine si un texte est exploitable pour l'extraction de triplets.
    Args:
        text (str): Le texte à analyser.
    Returns:
        bool: True si exploitable, False sinon.
    """
    # Vérifier des règles simples (longueur minimale, pas seulement des chiffres ou caractères spéciaux)
    if len(text.strip()) < 5 or text.isdigit() or text.isalpha():
        return False
    
    # Analyse syntaxique avec spaCy
    doc = nlp(text)
    
    # Vérifier s'il y a un verbe (indicateur d'une relation potentielle)
    has_verb = any(token.pos_ == "VERB" for token in doc)
    
    # Vérifier s'il y a au moins deux entités nommées ou des mots significatifs (noms, pronoms, etc.)
    has_subject_and_object = len([token for token in doc if token.pos_ in {"NOUN", "PROPN", "PRON"}]) >= 2
    
    # Exploitable si on trouve au moins un verbe et des entités ou sujets/objets potentiels
    return has_verb and has_subject_and_object

# Exemple de textes
texts = [
    "Paris is the capital of France.",  # Exploitable
    "2023",  # Non exploitable
    "Reference: A123",  # Non exploitable
    "Cats love milk.",  # Exploitable
    "Bonjour",  # Non exploitable
    "The meeting was held on Monday.",  # Exploitable
]

# Appliquer le pipeline
for text in texts:
    print(f"Text: \"{text}\" - Exploitable: {is_exploitable(text)}")
