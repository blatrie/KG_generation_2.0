"""
This module performs clustering and merging of triplets based on their similarity using the DBSCAN algorithm 
and cosine similarity. It is used during data storage in Memgraph. It includes functionality for preprocessing, clustering, and inserting new triplets 
into existing clusters.

Key Functions:
1. `is_good_triplet()`: Validates a triplet based on certain criteria (e.g., non-empty, non-redundant, not too long).
2. `preprocess_triplets_list()`: Removes duplicates and filters out invalid triplets from the list.
3. `initial_load()`: Performs initial clustering of triplets using DBSCAN.
4. `merge_within_cluster()`: Merges similar triplets within a cluster based on cosine similarity.
5. `merge_within_clusters()`: Merges triplets across all clusters.
6. `insert_new_triplet()`: Inserts a new triplet into the appropriate cluster or creates a new cluster.
7. `batch_merge_triplets()`: Processes and merges a batch of new triplets into existing clusters.

Main Workflow:
1. **Preprocessing**: Filters triplets by quality and removes duplicates.
2. **Clustering**: Uses DBSCAN to cluster triplets based on their embeddings generated by a pre-trained model.
3. **Merging**: Merges similar triplets within each cluster based on cosine similarity of their embeddings.
4. **Insertion**: Inserts new triplets into the most appropriate existing cluster, or creates a new cluster if no suitable match is found.
5. **Batch Processing**: Handles the insertion of a batch of new triplets and merges them accordingly.

Usage:
- `initial_load(triplets)`: Perform initial clustering of a list of triplets.
- `batch_merge_triplets(new_triplets, clusters)`: Add new triplets to existing clusters, ensuring that similar ones are merged.
"""

from sklearn.cluster import DBSCAN
from sklearn.metrics.pairwise import cosine_similarity
import numpy as np
from params import merge_model
fields = ['head', 'type', 'tail']


def is_good_triplet(triplet):
    """
    Check if a triplet meets certain quality criteria.
    
    Args:
        triplet (dict): A dictionary containing 'head', 'tail', and 'type' keys.
    
    Returns:
        bool: True if the triplet is valid, False otherwise.
    """
    # Destructure the triplet for cleaner access
    head, tail, triplet_type = triplet['head'].replace(".", ""), triplet['tail'].replace(".", ""), triplet['type'].replace(".", "")

    # Check conditions
    is_not_empty = head and tail and triplet_type
    is_not_long = len(head.split()) <= 4 and len(tail.split()) <= 4 and len(triplet_type.split()) <= 2
    is_not_same_tail_head = len(set([head, tail, triplet_type])) == 3

    return is_not_long and is_not_empty and is_not_same_tail_head

def preprocess_triplets_list(triplets):
    """
    Preprocess a list of triplets by removing duplicates and filtering out invalid triplets.
    
    Args:
        triplets (list): A list of triplets.
    
    Returns:
        list: A list of filtered and unique triplets.
    """

    kb_triplets_unique = [eval(triplet) for triplet in set(map(str, triplets))]
    filtered_triplets = [
        triplet for triplet in kb_triplets_unique
        if is_good_triplet(triplet)
    ]
    return filtered_triplets




def initial_load(triplets, model=merge_model):
    """
    Perform initial clustering of triplets using DBSCAN.
    
    Args:
        triplets (list): A list of triplets.
        model (SentenceTransformer): The model used to encode triplets.
    
    Returns:
        dict: A dictionary where keys are cluster labels and values are lists of triplets in that cluster.
    """
    if not triplets:
        return {}
    # Prepare Triplet Data
    triplets = preprocess_triplets_list(triplets)
        
    # Encode the elements for each field
    embeddings = [model.encode([ trp ]) for trp in triplets]
    # Cluster Using DBSCAN
    dbscan = DBSCAN(eps=0.5, min_samples=2, metric='cosine')  # Tune `eps` and `min_samples`
    cluster_labels = dbscan.fit_predict(np.array(embeddings).squeeze(1))

    # Assign Clusters
    clusters = {}
    for idx, label in enumerate(cluster_labels):
        if label not in clusters:
            clusters[label] = []
        clusters[label].append(triplets[idx])

    return clusters

# Intra-Cluster Merging
def merge_within_cluster(cluster_triplets, model=merge_model, threshold=0.75):
    """
    Merge similar triplets within a cluster based on cosine similarity.
    
    Args:
        cluster_triplets (list): A list of triplets in the same cluster.
        model (SentenceTransformer): The model used to encode triplets.
        threshold (float): The similarity threshold for merging.
    
    Returns:
        list: A list of merged triplets.
    """
    merged_triplets = []
    if not cluster_triplets:
        return merged_triplets
    while cluster_triplets:
        current = cluster_triplets.pop(0)
        current_embedding = model.encode([" ".join([current[field] for field in fields])])[0]
        similar_found = False
        for idx, triplet in enumerate(merged_triplets):
            triplet_embedding = model.encode([" ".join([triplet[field] for field in fields])])[0]
            similarity = cosine_similarity([current_embedding], [triplet_embedding]).flatten()[0]

            if similarity > threshold:
                similar_found = True
                break

        if not similar_found:
            merged_triplets.append(current)

    return merged_triplets 

def merge_within_clusters(clusters, model=merge_model):
    """
    Merge triplets within all clusters.
    
    Args:
        clusters (dict): A dictionary of clusters.
        model (SentenceTransformer): The model used to encode triplets.
    
    Returns:
        dict: A dictionary of merged clusters.
    """
    if clusters == {}:
        return {}
    return {label: merge_within_cluster(cluster, model) for label, cluster in clusters.items() if label != -1}



# Insertion Logic
def insert_new_triplet(new_triplet, clusters, 
                      model=merge_model, threshold=0.75):
    """
    Insert a new triplet into the appropriate cluster or create a new cluster if no similar triplet is found.
    
    Args:
        new_triplet (dict): The new triplet to insert.
        clusters (dict): The existing clusters.
        model (SentenceTransformer): The model used to encode triplets.
        threshold (float): The similarity threshold for merging.
    
    Returns:
        tuple: A tuple containing the cluster ID and the similar triplet (if found).
    """
    new_embedding = model.encode([ new_triplet])[0]
    for cluster_id, cluster_triplets in clusters.items():
        cluster_embeddings = model.encode(cluster_triplets)
        similarities = cosine_similarity([new_embedding], cluster_embeddings).flatten()
        if np.max(similarities) > threshold:
            # Similar triplet found, handle merge or discard
            return clusters, False # not effectively added
    
    # No similar triplet found, create a new cluster
    if clusters == {}: 
        new_cluster_id = 0
    else : 
        new_cluster_id = max(clusters.keys()) + 1
    #new_cluster_id = max(clusters.keys()) + 1
    clusters[new_cluster_id] = [new_triplet]
    return clusters, True # effectively added

def batch_merge_triplets(new_triplets, clusters, 
                        model=merge_model, threshold=0.75):
    """
    Insert a batch of new triplets into the clusters and log the results.
    
    Args:
        new_triplets (list): A list of new triplets to insert.
        clusters (dict): The existing clusters.
        model (SentenceTransformer): The model used to encode triplets.
        threshold (float): The similarity threshold for merging.
    
    Returns:
        tuple: A tuple containing the log of similar triplets and the updated clusters.
    """
    # print("cluster before adding", clusters)
    added_triplets = []
    new_triplets = preprocess_triplets_list(new_triplets)
    updated_clusters = clusters
    for new_triplet in new_triplets:
        updated_clusters,  effectively_added = insert_new_triplet(new_triplet, clusters, model, threshold)
        if effectively_added :
            added_triplets.append(new_triplet)
    return merge_within_clusters(updated_clusters), added_triplets
